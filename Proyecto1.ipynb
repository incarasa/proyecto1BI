{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17dc9b3e-1537-4c47-a1c7-659a6ca32ebd",
   "metadata": {},
   "source": [
    "# Avance 1: Proyecto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113470f4-f2ea-4032-8593-9ca9003a697d",
   "metadata": {},
   "source": [
    "## Entendimiento y preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5845ad7d-b8b6-42b2-a950-6f1282554260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0908f44-b640-4a45-baa6-ee9bc8e81e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textos</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Aprendizaje\" y \"educación\" se consideran sinó...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Para los niños más pequeños (bebés y niños peq...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Además, la formación de especialistas en medic...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>En los países de la OCDE se tiende a pasar de ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Este grupo se centró en las personas que padec...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              textos  labels\n",
       "0  \"Aprendizaje\" y \"educación\" se consideran sinó...       4\n",
       "1  Para los niños más pequeños (bebés y niños peq...       4\n",
       "2  Además, la formación de especialistas en medic...       3\n",
       "3  En los países de la OCDE se tiende a pasar de ...       4\n",
       "4  Este grupo se centró en las personas que padec...       3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ruta del archivo\n",
    "file_path = \"Datos_proyecto.xlsx\"\n",
    "\n",
    "# Cargar el Excel\n",
    "df = pd.read_excel(file_path, sheet_name=\"Sheet1\")\n",
    "\n",
    "# Mostrar las primeras filas\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c745257a-6827-459c-9579-06bb1a47ef5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2424 entries, 0 to 2423\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   textos  2424 non-null   object\n",
      " 1   labels  2424 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 38.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Ver información general\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8d5352-1f11-4c1f-86f3-a91de8ee52fa",
   "metadata": {},
   "source": [
    "Separamos nuestros conjuntos de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ca85c6a-9b85-42fc-b937-d4a8910ed82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"textos\"], df[\"labels\"], test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39a5275-1fa5-42d2-a4e1-467db269fc3e",
   "metadata": {},
   "source": [
    "Ahora empezaremos construyendo el pipeline de preprocesamiento y entrenamiento de nuestros datos. Pero antes revisaremos TfidfVectorizer que nos ayudará a preprocesar nuestras entradas y a construir nuestra bag of words (BOW)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cf88ce2-0259-4e0b-86d0-fdf730fe003f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\incar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(306,\n",
       " ['a',\n",
       "  'al',\n",
       "  'algo',\n",
       "  'algunas',\n",
       "  'algunos',\n",
       "  'ante',\n",
       "  'antes',\n",
       "  'como',\n",
       "  'con',\n",
       "  'contra',\n",
       "  'cual',\n",
       "  'cuando',\n",
       "  'de',\n",
       "  'del',\n",
       "  'desde',\n",
       "  'donde',\n",
       "  'durante',\n",
       "  'e',\n",
       "  'el',\n",
       "  'ella'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Se preparan las stopwords en español para utilizar en vectorizer\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Se quitan los acentos de las stopwords, lo cual también es importante (evitar warnings)\n",
    "def strip_accents(s: str) -> str:\n",
    "    return ''.join(c for c in unicodedata.normalize('NFKD', s)\n",
    "                   if not unicodedata.combining(c))\n",
    "\n",
    "\n",
    "spanish_stopwords = sorted({ strip_accents(w.lower()) for w in stopwords.words('spanish') })\n",
    "len(spanish_stopwords), spanish_stopwords[:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a626099b-f377-4079-a736-ae46781a6fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras en el vocabulario:\n",
      " ['cada' 'cada vez' 'forma' 'formación' 'mental' 'mentales' 'más' 'nivel'\n",
      " 'ocde' 'pueden' 'salud' 'salud mental' 'servicios' 'servicios salud'\n",
      " 'trastornos' 'trastornos mentales' 'tratamiento' 'vez' 'vez más']\n"
     ]
    }
   ],
   "source": [
    "# Usamos solo una muestra pequeña de tus datos para verlos \"a mano\"\n",
    "muestra = df[\"textos\"].head(5)\n",
    "\n",
    "# Crear el vectorizador\n",
    "vectorizer = TfidfVectorizer(\n",
    "            stop_words=spanish_stopwords,   # stop words en español\n",
    "            lowercase=True,                 # minúsculas\n",
    "            strip_accents='unicode',      # quitar los acentos: educación -> educacion\n",
    "            min_df=2,                       # ignora términos que aparezcan en <2 docs\n",
    "            max_df=0.9,                     # ignora términos muy frecuentes >90%\n",
    "            ngram_range=(1,2),              # se incluyen bigramas\n",
    "            sublinear_tf=True,\n",
    "            max_features=20000,           # evita sobrecargas por bigramas\n",
    ")\n",
    "\n",
    "# Ajustar y transformar\n",
    "X_tfidf = vectorizer.fit_transform(muestra)\n",
    "\n",
    "# Ver las palabras del vocabulario que creó TF-IDF\n",
    "print(\"Palabras en el vocabulario:\\n\", vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891305f2-b4f7-46d5-9610-6c400cfaae77",
   "metadata": {},
   "source": [
    "## Modelado y Evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9875812a-a17b-4bae-9f11-e238380e9770",
   "metadata": {},
   "source": [
    "Ahora construiremos los pipelines para el preprocesamiento y entrenamiento de nuestros datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f1215c6-e8f1-4345-b6b0-6e0e4ff6ca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    stop_words=sorted(spanish_stopwords),\n",
    "    lowercase=True,\n",
    "    strip_accents='unicode',\n",
    "    min_df=2,          # ignora términos muy raros\n",
    "    max_df=0.9,        # ignora términos demasiado frecuentes\n",
    "    ngram_range=(1,2), # unigrams + bigrams\n",
    "    sublinear_tf=True, # tf = 1 + log(tf) AJUSTE PARA EL CONTEO, MEJOR LOGARITMICO\n",
    "    max_features=20000 # límite para no explotar RAM\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da88b59f-3c1c-4904-ab33-2ab29737dd04",
   "metadata": {},
   "source": [
    "**Pipeline 1 (Regresión Logística)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c22933f-32a8-4a51-aaca-b843ac2ee131",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\incar\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Regresión Logística ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.956     0.964     0.960       112\n",
      "           3      0.971     0.982     0.976       168\n",
      "           4      0.995     0.980     0.988       205\n",
      "\n",
      "    accuracy                          0.977       485\n",
      "   macro avg      0.974     0.976     0.975       485\n",
      "weighted avg      0.978     0.977     0.977       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Pipeline: TF-IDF + Logistic Regression\n",
    "pipe_logreg = Pipeline([\n",
    "    (\"tfidf\", tfidf),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        max_iter=2000,\n",
    "        class_weight=\"balanced\",  # maneja desbalance de clases\n",
    "        multi_class=\"auto\"\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipe_logreg.fit(X_train, y_train)\n",
    "y_pred_logreg = pipe_logreg.predict(X_test)\n",
    "\n",
    "print(\"=== Regresión Logística ===\")\n",
    "print(classification_report(y_test, y_pred_logreg, digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d447bc94-a1c5-49d6-94af-a2ed75d83bdb",
   "metadata": {},
   "source": [
    "**Pipeline 2 (SVM Máquinas de Vectores de Soporte)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "796c8eac-70ec-452a-98ed-41bab109bfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Support Vector Machine (Lineal) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.956     0.964     0.960       112\n",
      "           3      0.965     0.982     0.973       168\n",
      "           4      0.995     0.976     0.985       205\n",
      "\n",
      "    accuracy                          0.975       485\n",
      "   macro avg      0.972     0.974     0.973       485\n",
      "weighted avg      0.976     0.975     0.975       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Pipeline: TF-IDF + Linear SVM\n",
    "pipe_svm = Pipeline([\n",
    "    (\"tfidf\", tfidf),\n",
    "    (\"clf\", LinearSVC(class_weight=\"balanced\", dual=True))\n",
    "])\n",
    "\n",
    "pipe_svm.fit(X_train, y_train)\n",
    "y_pred_svm = pipe_svm.predict(X_test)\n",
    "\n",
    "print(\"=== Support Vector Machine (Lineal) ===\")\n",
    "print(classification_report(y_test, y_pred_svm, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a349ff35-a7fd-410c-9fda-5b549df60c42",
   "metadata": {},
   "source": [
    "**Pipeline 3 (Bayes Ingenuo Multinomial)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fb3392c-5bd9-4995-8df9-66fb3b8e81a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Naive Bayes Multinomial ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.969     0.830     0.894       112\n",
      "           3      0.943     0.976     0.959       168\n",
      "           4      0.940     0.985     0.962       205\n",
      "\n",
      "    accuracy                          0.946       485\n",
      "   macro avg      0.950     0.931     0.938       485\n",
      "weighted avg      0.947     0.946     0.945       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Pipeline: TF-IDF + Multinomial Naive Bayes\n",
    "pipe_nb = Pipeline([\n",
    "    (\"tfidf\", tfidf),\n",
    "    (\"clf\", MultinomialNB(alpha=0.5))  # alpha suaviza probabilidades (HIPERPARAMETRO?)\n",
    "])\n",
    "\n",
    "pipe_nb.fit(X_train, y_train)\n",
    "y_pred_nb = pipe_nb.predict(X_test)\n",
    "\n",
    "print(\"=== Naive Bayes Multinomial ===\")\n",
    "print(classification_report(y_test, y_pred_nb, digits=3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
